{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70558a2d",
   "metadata": {},
   "source": [
    "\n",
    "# literature review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4368c",
   "metadata": {},
   "source": [
    "This notebook is for LLM project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fc6cd6",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Name: Interstitial lung disease diagnosis and prognosis using an AI system integrating longitudinal data\n",
    "\n",
    "Link: https://doi.org/10.1038/s41467-023-37720-5\n",
    "\n",
    "Abstract: \n",
    "\n",
    "This study developed an artificial intelligence system to help diagnose and predict outcomes for interstitial lung disease (ILD) patients. The process has three main steps:\n",
    "\n",
    "- ** Image analysis: Deep learning models (CNN and Vision Transformer) automatically examine chest CT scans to find patterns linked to different ILD types.\n",
    "\n",
    "- ** Clinical data analysis: Machine learning algorithms (MLP, XGBoost, SVM) analyze patient information like age, smoking history, and lung function to help identify the ILD subtype.\n",
    "\n",
    "- ** Combined prediction: The system merges image and clinical data for a more accurate diagnosis, and uses models (Transformer, LSTM) to track patient data over time and predict three-year survival chances.\n",
    "\n",
    "\n",
    "## 2.\n",
    "\n",
    "Name: Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning\n",
    "\n",
    "Link: https://arxiv.org/abs/2210.06044\n",
    "\n",
    "## 3.\n",
    "\n",
    "Name: MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant\n",
    "\n",
    "### 4.\n",
    "\n",
    "Name: Survey on natural language processing in medical image analysis\n",
    "\n",
    "PMID: 36097765\n",
    "\n",
    "### 5.\n",
    "\n",
    "Name: MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided\n",
    "Diffusion with Visual Invariant\n",
    "\n",
    "\n",
    "### 6.\n",
    "\n",
    "Name： MedCLIP: Contrastive Learning from Unpaired Medical Images and Text\n",
    "\n",
    "### 7.\n",
    "\n",
    "Name: Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning\n",
    "\n",
    "\n",
    "\n",
    "这个思路完全具备科研价值，可以形成一篇有意义的论文。关键在于设计合理的实验来验证“弱监督标签＋深度视觉模型”方案的有效性。以下是一个可行的研究框架和要点：\n",
    "\n",
    "研究动机与创新点\n",
    "\n",
    "动机：临床报告文本格式多样、非结构化，传统标准化标注难以大规模获取；自动化解读报告（如 NegBio 提取标签）能生成海量弱监督标签。\n",
    "\n",
    "创新点：首次系统地评估“报告弱监督标签 → ResNet → 图像分类”流程，并分析噪声标签对模型鲁棒性的影响。\n",
    "\n",
    "数据与标签获取\n",
    "\n",
    "选用 MIMIC-CXR（带报告）或 IU X-ray。\n",
    "\n",
    "用 NegBio／NegSpacy 提取疾病实体（如肺实变、气胸、积液等），并处理否定、历史等语义，生成图像级多标签弱标注。\n",
    "\n",
    "视觉模型与训练\n",
    "\n",
    "模型骨干：ResNet-50/101，加入通道或空间注意力模块可选。\n",
    "\n",
    "训练策略：\n",
    "\n",
    "仅弱监督标签训练\n",
    "\n",
    "少量人工精标签微调\n",
    "\n",
    "对比完全监督与弱监督性能\n",
    "\n",
    "实验设计\n",
    "\n",
    "定量指标：多标签分类的 AUC、准确率；标签噪声率与模型性能曲线\n",
    "\n",
    "消融研究：NegBio 标签质量（含噪 vs 经人工校正）对最终分类效果的贡献\n",
    "\n",
    "可视化：Grad-CAM 展示模型关注区域，与报告描述对齐程度\n",
    "\n",
    "结果与讨论\n",
    "\n",
    "如果弱监督模型在常见异常（如气胸、实变）上与人工监督相近，即表明深度模型对报告噪声具有鲁棒性\n",
    "\n",
    "分析失败案例，探讨如何进一步改进文本NER质量或模型架构\n",
    "\n",
    "临床意义\n",
    "\n",
    "证明可利用现成报告、大规模弱监督生成影像标签，降低人工标注成本\n",
    "\n",
    "为未来医学影像多模态自监督、半监督研究提供数据/方法范式\n",
    "\n",
    "结论：建议按照上述框架撰写，从数据获取、弱监督标签生成、模型训练、定量评估到可视化分析，全面论证该思路的可行性和优势。这样的工作既有技术创新，也具备显著的临床应用价值，非常适合投稿到医学影像或人工智能顶会/期刊。\n",
    "\n",
    "--------------------------------------------------------------------------------------------\n",
    "\n",
    "多模态人工智能以及大模型在biomedical data上的应用\n",
    "\n",
    "Imaging Data: X-Ray, Ultrasound, MRI/CT, Histology\n",
    "\n",
    "Non-Imaging Data: EHR, Rports, Biosensor Data Genomic Data\n",
    "\n",
    "Multimodal biomedical AI Nature Medicine : 追加医疗，个性诊疗，ai问诊\n",
    "\n",
    "\n",
    "multimodal data fusion\n",
    "\n",
    "可以进行模拟，通过多种数据观测，来进行病症的预测或者诊断，预防\n",
    "\n",
    "multimodal data interconnection: 比如文本生成，图像生成\n",
    "\n",
    "LLM： 从22年出现chat以后，就有人提出了在医疗领域的使用上的畅想\n",
    "\n",
    "bottleneck of supervised learning: \n",
    "1. label比较稀缺，医生标注，成本高昂 (垂类数据)\n",
    "2. radiology reports 提供了重要的帮助\n",
    "\n",
    "1. 22年MGCA 开发了多尺度的对齐： pretrain dataset MIMIC-CXR\n",
    "进行了分类，检测与分割， 比clip好\n",
    "\n",
    "2. MIXED type of annotations\n",
    "can we leverge these diverse annotations to enchance performance of foundation model?\n",
    "DCXFM\n",
    "\n",
    "数据集\n",
    "mimi-CXR\n",
    "VinBigData\n",
    "CANDID-PTX\n",
    "\n",
    "mimic \n",
    "cheXpert\n",
    "padchest\n",
    "chexlocalize\n",
    "ms-cxr\n",
    "rsna\n",
    "covid rural\n",
    "\n",
    "3. 图像的自动解读和报告生成\n",
    "\n",
    "longitudinal information in image-text pairs\n",
    "\n",
    "HERGen\n",
    "\n",
    "问题：如何高效的利用有效数据\n",
    "\n",
    "4. Extension: 3D CT/MRI and mdeical report joint learning\n",
    "\n",
    "5. Bridging Radiological Images and Factors\n",
    "\n",
    "6. Multi-scale ECG-text pretrained models\n",
    "\n",
    "\n",
    "二： foundation models are transforming healthcare\n",
    "\n",
    "downstream\n",
    "\n",
    "democratizing LLM-BASED Graph \n",
    "\n",
    "agent AI \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
